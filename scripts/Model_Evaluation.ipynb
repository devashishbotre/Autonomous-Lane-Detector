{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 2840219,
          "sourceType": "datasetVersion",
          "datasetId": 1724942
        },
        {
          "sourceId": 11355450,
          "sourceType": "datasetVersion",
          "datasetId": 7095067
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Model Evaluation",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devashishbotre/Autonomous-Lane-Detector/blob/main/scripts/Model_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "9cgVkA5xG5nz"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "manideep1108_tusimple_path = kagglehub.dataset_download('manideep1108/tusimple')\n",
        "kingster9_models_path = kagglehub.dataset_download('kingster9/models')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "jBQU3GAVG5n1"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import time\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from model_module import RESA, Decoder, LaneNet\n",
        "\n",
        "IMG_HEIGHT = 720\n",
        "IMG_WIDTH = 1280\n",
        "NUM_CLASSES = 2\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-10T13:33:18.541748Z",
          "iopub.execute_input": "2025-04-10T13:33:18.542759Z",
          "iopub.status.idle": "2025-04-10T13:33:18.547879Z",
          "shell.execute_reply.started": "2025-04-10T13:33:18.542722Z",
          "shell.execute_reply": "2025-04-10T13:33:18.547109Z"
        },
        "id": "m4jYZeNeG5n2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class RESA(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(RESA, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, in_channels, 1, padding=0)\n",
        "        self.bn = nn.BatchNorm2d(in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.refine_conv = nn.Conv2d(in_channels, in_channels, 3, padding=1, groups=in_channels)\n",
        "        self.refine_bn = nn.BatchNorm2d(in_channels)\n",
        "        self.shifts = [\n",
        "            (1, 0), (2, 0), (3, 0),\n",
        "            (-1, 0), (-2, 0), (-3, 0),\n",
        "            (0, -1), (0, -2), (0, -3),\n",
        "            (0, 1), (0, 2), (0, 3)\n",
        "        ]\n",
        "\n",
        "        distances = torch.tensor([(i**2 + j**2) for i, j in self.shifts], dtype=torch.float32)\n",
        "        self.weights = torch.exp(-distances / (2 * 1.5**2)).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        contributions = []\n",
        "        for (shift_h, shift_w), weight in zip(self.shifts, self.weights):\n",
        "            shifted = torch.roll(x, shifts=(shift_h, shift_w), dims=(2, 3))\n",
        "            contrib = self.relu(self.bn(self.conv(shifted)))\n",
        "            contrib = self.relu(self.refine_bn(self.refine_conv(contrib)))\n",
        "            contributions.append(contrib * weight)\n",
        "\n",
        "        out = x + 0.5 * sum(contributions) / sum(self.weights)\n",
        "        return out\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.Up1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels // 2, 3, padding=1),\n",
        "            nn.BatchNorm2d(in_channels // 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        )\n",
        "        self.Up2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels // 2, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        )\n",
        "\n",
        "        self.smooth_conv = nn.Conv2d(out_channels, out_channels, 5, padding=2, groups=out_channels)\n",
        "        self.smooth_bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.thin1 = nn.Conv2d(in_channels // 2, in_channels // 2, 3, padding=1, groups=in_channels // 2)\n",
        "        self.thin2 = nn.Conv2d(out_channels, out_channels, 3, padding=1, groups=out_channels)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.Up1(x)\n",
        "        x = x + torch.sigmoid(self.thin1(x)) * x\n",
        "        x = self.Up2(x)\n",
        "        x = x + torch.sigmoid(self.thin2(x)) * x\n",
        "\n",
        "        x = self.relu(self.smooth_bn(self.smooth_conv(x)))\n",
        "        return x\n",
        "\n",
        "class LaneNet(nn.Module):\n",
        "    def __init__(self, num_classes=NUM_CLASSES, k_iterations=4):\n",
        "        super(LaneNet, self).__init__()\n",
        "        resnet = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
        "        self.encoder = nn.Sequential(\n",
        "            resnet.conv1,\n",
        "            resnet.bn1,\n",
        "            resnet.relu,\n",
        "            resnet.maxpool,\n",
        "            resnet.layer1,\n",
        "            resnet.layer2,\n",
        "            resnet.layer3,\n",
        "            resnet.layer4\n",
        "        )\n",
        "\n",
        "        self.resa_layers = nn.ModuleList([RESA(512) for _ in range(k_iterations)])\n",
        "        self.decoder = Decoder(512, 256)\n",
        "        self.seg_head = nn.Conv2d(256, num_classes, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        for resa in self.resa_layers:\n",
        "            x = resa(x)\n",
        "        x = self.decoder(x)\n",
        "        seg_out = self.seg_head(x)\n",
        "        seg_out = F.interpolate(seg_out, size=(IMG_HEIGHT, IMG_WIDTH), mode='bilinear', align_corners=True)\n",
        "        seg_out = F.avg_pool2d(seg_out, kernel_size=3, padding=1, stride=1)\n",
        "        return seg_out"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-10T13:20:22.227847Z",
          "iopub.execute_input": "2025-04-10T13:20:22.228192Z",
          "iopub.status.idle": "2025-04-10T13:20:22.242535Z",
          "shell.execute_reply.started": "2025-04-10T13:20:22.228173Z",
          "shell.execute_reply": "2025-04-10T13:20:22.241923Z"
        },
        "id": "FBJ8yb9lG5n2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class TuSimpleDataset(Dataset):\n",
        "    def __init__(self, json_files, img_dir, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.annotations = []\n",
        "        total_annotations = 0\n",
        "        for json_file in json_files:\n",
        "            if not os.path.exists(json_file):\n",
        "                print(f\"Warning: JSON file not found: {json_file}\")\n",
        "                continue\n",
        "            with open(json_file, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "                total_annotations += len(lines)\n",
        "                for line in lines:\n",
        "                    ann = json.loads(line)\n",
        "                    img_path = os.path.join(self.img_dir, ann['raw_file'])\n",
        "                    if os.path.exists(img_path):\n",
        "                        self.annotations.append(ann)\n",
        "                    else:\n",
        "                        print(f\"Warning: Image not found: {img_path}\")\n",
        "        print(f\"Total annotations in JSON: {total_annotations}\")\n",
        "        print(f\"Valid images found: {len(self.annotations)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ann = self.annotations[idx]\n",
        "        img_path = os.path.join(self.img_dir, ann['raw_file'])\n",
        "\n",
        "        # Load and resize image\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None:\n",
        "            print(f\"Error: Failed to load image: {img_path}\")\n",
        "            image = np.zeros((IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.uint8)\n",
        "        image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        mask = np.zeros((IMG_HEIGHT, IMG_WIDTH), dtype=np.uint8)\n",
        "        for lane in ann['lanes']:\n",
        "            points = [(x, y) for x, y in zip(lane, ann['h_samples']) if x != -2 and 0 <= y < IMG_HEIGHT and 0 <= x < IMG_WIDTH]\n",
        "            if len(points) > 1:\n",
        "                points = np.array(points, dtype=np.int32)\n",
        "                cv2.polylines(mask, [points], False, 1, 1)\n",
        "\n",
        "        image = torch.from_numpy(image.transpose(2, 0, 1)).float() / 255.0\n",
        "        mask = torch.from_numpy(mask).long()\n",
        "\n",
        "        return image, mask, ann\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images, masks, anns = zip(*batch)\n",
        "    images = torch.stack(images, 0)\n",
        "    masks = torch.stack(masks, 0)\n",
        "    return images, masks, anns"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-10T13:31:51.747658Z",
          "iopub.execute_input": "2025-04-10T13:31:51.747931Z",
          "iopub.status.idle": "2025-04-10T13:31:51.757852Z",
          "shell.execute_reply.started": "2025-04-10T13:31:51.74791Z",
          "shell.execute_reply": "2025-04-10T13:31:51.757089Z"
        },
        "id": "eiJRQnntG5n3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, device, data_loader):\n",
        "    model.eval()\n",
        "    total_f1, total_acc, total_time = 0.0, 0.0, 0.0\n",
        "    num_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks, _ in tqdm(data_loader, desc=\"Evaluating on Training Data\"):\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "            start_time = time.time()\n",
        "            outputs = model(images)\n",
        "            end_time = time.time()\n",
        "            inference_time = end_time - start_time\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "            masks = masks.cpu().numpy()\n",
        "\n",
        "            batch_size = images.size(0)\n",
        "            for i in range(batch_size):\n",
        "                pred_flat = preds[i].flatten()\n",
        "                mask_flat = masks[i].flatten()\n",
        "\n",
        "                f1 = f1_score(mask_flat, pred_flat, average='binary', zero_division=0)\n",
        "                acc = accuracy_score(mask_flat, pred_flat)\n",
        "\n",
        "                total_f1 += f1\n",
        "                total_acc += acc\n",
        "                total_time += inference_time / batch_size\n",
        "                num_samples += 1\n",
        "\n",
        "    avg_f1 = total_f1 / num_samples\n",
        "    avg_acc = total_acc / num_samples\n",
        "    avg_inference_time = total_time / num_samples\n",
        "\n",
        "    return avg_f1, avg_acc, avg_inference_time"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-10T13:23:27.514967Z",
          "iopub.execute_input": "2025-04-10T13:23:27.515263Z",
          "iopub.status.idle": "2025-04-10T13:23:27.522042Z",
          "shell.execute_reply.started": "2025-04-10T13:23:27.515242Z",
          "shell.execute_reply": "2025-04-10T13:23:27.521261Z"
        },
        "id": "7ZZRC4bzG5n3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = LaneNet(num_classes=NUM_CLASSES).to(device)\n",
        "model_path = \"/kaggle/input/models/lane_model_final (2).pth\"\n",
        "if os.path.exists(model_path):\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
        "    print(f\"Loaded model weights from {model_path}\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"Model weights not found at {model_path}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-10T13:27:19.325795Z",
          "iopub.execute_input": "2025-04-10T13:27:19.326062Z",
          "iopub.status.idle": "2025-04-10T13:27:21.498779Z",
          "shell.execute_reply.started": "2025-04-10T13:27:19.326042Z",
          "shell.execute_reply": "2025-04-10T13:27:21.498163Z"
        },
        "id": "SelkCA1YG5n3",
        "outputId": "9eaa1fea-4ed4-4e25-f2e2-6156aad57827"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Loaded model weights from /kaggle/input/models/lane_model_final (2).pth\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/kaggle/input/tusimple/TUSimple/train_set'\n",
        "json_files = [os.path.join(data_dir, f) for f in ['label_data_0313.json',\n",
        "                                                     'label_data_0531.json',\n",
        "                                                     'label_data_0601.json']]\n",
        "train_dataset = TuSimpleDataset(json_files, data_dir)\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=False, num_workers=4, collate_fn=collate_fn)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-10T13:31:58.109767Z",
          "iopub.execute_input": "2025-04-10T13:31:58.110016Z",
          "iopub.status.idle": "2025-04-10T13:32:27.713885Z",
          "shell.execute_reply.started": "2025-04-10T13:31:58.110001Z",
          "shell.execute_reply": "2025-04-10T13:32:27.713102Z"
        },
        "id": "q-i9F76jG5n4",
        "outputId": "013e26c1-2bbe-443e-9fe1-ef4b352e2507"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total annotations in JSON: 3626\nValid images found: 3626\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "avg_f1, avg_acc, avg_inference_time = evaluate_model(model, device, train_loader)\n",
        "\n",
        "print(f\"Average F1 Score (Training Data): {avg_f1:.4f}\")\n",
        "print(f\"Average Accuracy (Training Data): {avg_acc:.4f}\")\n",
        "print(f\"Average Inference Time per Image (Training Data): {avg_inference_time:.6f} seconds\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-10T13:33:22.615651Z",
          "iopub.execute_input": "2025-04-10T13:33:22.616197Z",
          "iopub.status.idle": "2025-04-10T14:17:06.697032Z",
          "shell.execute_reply.started": "2025-04-10T13:33:22.616164Z",
          "shell.execute_reply": "2025-04-10T14:17:06.696051Z"
        },
        "id": "49nEcwLjG5n4",
        "outputId": "72964175-f329-463a-bcba-ea87f14cdf29"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Evaluating on Training Data: 100%|██████████| 907/907 [43:44<00:00,  2.89s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Average F1 Score (Training Data): 0.3197\nAverage Accuracy (Training Data): 0.9913\nAverage Inference Time per Image (Training Data): 0.005836 seconds\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "k0GMtLnvG5n5"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}