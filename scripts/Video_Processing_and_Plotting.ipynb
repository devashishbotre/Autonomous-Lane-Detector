{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 2840219,
          "sourceType": "datasetVersion",
          "datasetId": 1724942
        },
        {
          "sourceId": 11344559,
          "sourceType": "datasetVersion",
          "datasetId": 7098108
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Video Processing and Plotting",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devashishbotre/Autonomous-Lane-Detector/blob/main/scripts/Video_Processing_and_Plotting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "nxHolU_BPMny"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "manideep1108_tusimple_path = kagglehub.dataset_download('manideep1108/tusimple')\n",
        "devashishbotre_models_path = kagglehub.dataset_download('devashishbotre/models')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "YXj3OGntPMnz"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "from tqdm import tqdm\n",
        "\n",
        "IMG_HEIGHT, IMG_WIDTH = 720, 1280  # Adjust to match your model's expected input size\n",
        "NUM_CLASSES = 2  # Background and lane"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-09T19:46:25.45813Z",
          "iopub.execute_input": "2025-04-09T19:46:25.458379Z",
          "iopub.status.idle": "2025-04-09T19:46:25.46294Z",
          "shell.execute_reply.started": "2025-04-09T19:46:25.458351Z",
          "shell.execute_reply": "2025-04-09T19:46:25.462015Z"
        },
        "id": "IYWkEplqPMn0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class RESA(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(RESA, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, in_channels, 1, padding=0)\n",
        "        self.bn = nn.BatchNorm2d(in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.refine_conv = nn.Conv2d(in_channels, in_channels, 3, padding=1, groups=in_channels)\n",
        "        self.refine_bn = nn.BatchNorm2d(in_channels)\n",
        "        self.shifts = [\n",
        "            (1, 0), (2, 0), (3, 0),    # up-to-down\n",
        "            (-1, 0), (-2, 0), (-3, 0), # down-to-up\n",
        "            (0, -1), (0, -2), (0, -3), # right-to-left\n",
        "            (0, 1), (0, 2), (0, 3)     # left-to-right\n",
        "        ]\n",
        "        distances = torch.tensor([(i**2 + j**2) for i, j in self.shifts], dtype=torch.float32)\n",
        "        self.weights = torch.exp(-distances / (2 * 1.5**2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        device = x.device\n",
        "        self.weights = self.weights.to(device)\n",
        "        contributions = []\n",
        "        for (shift_h, shift_w), weight in zip(self.shifts, self.weights):\n",
        "            shifted = torch.roll(x, shifts=(shift_h, shift_w), dims=(2, 3))\n",
        "            contrib = self.relu(self.bn(self.conv(shifted)))\n",
        "            contrib = self.relu(self.refine_bn(self.refine_conv(contrib)))\n",
        "            contributions.append(contrib * weight)\n",
        "        out = x + 0.5 * sum(contributions) / sum(self.weights)\n",
        "        return out"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-09T19:46:25.463672Z",
          "iopub.execute_input": "2025-04-09T19:46:25.463969Z",
          "iopub.status.idle": "2025-04-09T19:46:25.527366Z",
          "shell.execute_reply.started": "2025-04-09T19:46:25.463948Z",
          "shell.execute_reply": "2025-04-09T19:46:25.526486Z"
        },
        "id": "YM93iXDxPMn0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.Up1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels // 2, 3, padding=1),\n",
        "            nn.BatchNorm2d(in_channels // 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        )\n",
        "        self.Up2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels // 2, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        )\n",
        "        self.smooth_conv = nn.Conv2d(out_channels, out_channels, 5, padding=2, groups=out_channels)\n",
        "        self.smooth_bn = nn.BatchNorm2d(out_channels)\n",
        "        self.thin1 = nn.Conv2d(in_channels // 2, in_channels // 2, 3, padding=1, groups=in_channels // 2)\n",
        "        self.thin2 = nn.Conv2d(out_channels, out_channels, 3, padding=1, groups=out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.Up1(x)\n",
        "        x = x + torch.sigmoid(self.thin1(x)) * x\n",
        "        x = self.Up2(x)\n",
        "        x = x + torch.sigmoid(self.thin2(x)) * x\n",
        "        x = self.relu(self.smooth_bn(self.smooth_conv(x)))\n",
        "        return x"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-09T19:46:25.528469Z",
          "iopub.execute_input": "2025-04-09T19:46:25.528841Z",
          "iopub.status.idle": "2025-04-09T19:46:25.541487Z",
          "shell.execute_reply.started": "2025-04-09T19:46:25.528801Z",
          "shell.execute_reply": "2025-04-09T19:46:25.540684Z"
        },
        "id": "MPJMx45kPMn1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class LaneNet(nn.Module):\n",
        "    def __init__(self, num_classes=NUM_CLASSES, k_iterations=4):\n",
        "        super(LaneNet, self).__init__()\n",
        "        resnet = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
        "        self.encoder = nn.Sequential(\n",
        "            resnet.conv1, resnet.bn1, resnet.relu, resnet.maxpool,\n",
        "            resnet.layer1, resnet.layer2, resnet.layer3, resnet.layer4\n",
        "        )\n",
        "        self.resa_layers = nn.ModuleList([RESA(512) for _ in range(k_iterations)])\n",
        "        self.decoder = Decoder(512, 256)\n",
        "        self.seg_head = nn.Conv2d(256, num_classes, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        for resa in self.resa_layers:\n",
        "            x = resa(x)\n",
        "        x = self.decoder(x)\n",
        "        seg_out = self.seg_head(x)\n",
        "        seg_out = F.interpolate(seg_out, size=(IMG_HEIGHT, IMG_WIDTH), mode='bilinear', align_corners=True)\n",
        "        seg_out = F.avg_pool2d(seg_out, kernel_size=3, padding=1, stride=1)\n",
        "        return seg_out"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-09T19:46:25.542339Z",
          "iopub.execute_input": "2025-04-09T19:46:25.542636Z",
          "iopub.status.idle": "2025-04-09T19:46:25.561716Z",
          "shell.execute_reply.started": "2025-04-09T19:46:25.542603Z",
          "shell.execute_reply": "2025-04-09T19:46:25.560979Z"
        },
        "id": "mHnDni3dPMn1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def overlay_mask(image, mask, alpha=0.5):\n",
        "    mask_colored = np.zeros_like(image)\n",
        "    mask_colored[mask == 1] = [0, 255, 0]  # Green for lanes\n",
        "    overlay = cv2.addWeighted(image, 1.0, mask_colored, alpha, 0.0)\n",
        "    return overlay\n",
        "\n",
        "\n",
        "def numeric_sort_key(name):\n",
        "    return int(os.path.splitext(name)[0])\n",
        "\n",
        "# Process directory function\n",
        "def process_directory(root_dir, model, device, output_dir=\"output_videos\"):\n",
        "    if not os.path.exists(root_dir):\n",
        "        raise FileNotFoundError(f\"Root directory {root_dir} does not exist\")\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Initialize single video writers for all frames\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    original_video = cv2.VideoWriter(\n",
        "        os.path.join(output_dir, \"original_video_all.mp4\"), fourcc, 20.0, (IMG_WIDTH, IMG_HEIGHT)\n",
        "    )\n",
        "    lane_video = cv2.VideoWriter(\n",
        "        os.path.join(output_dir, \"lane_detected_video_all.mp4\"), fourcc, 20.0, (IMG_WIDTH, IMG_HEIGHT)\n",
        "    )\n",
        "    subdirs = sorted(\n",
        "        [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))],\n",
        "        key=lambda x: int(x)\n",
        "    )\n",
        "\n",
        "    total_frames_processed = 0\n",
        "\n",
        "    for subdir in tqdm(subdirs, desc=\"Processing subdirectories\"):\n",
        "        subdir_path = os.path.join(root_dir, subdir)\n",
        "        frames = sorted(\n",
        "            [f for f in os.listdir(subdir_path) if f.endswith('.jpg')],\n",
        "            key=numeric_sort_key\n",
        "        )\n",
        "\n",
        "        if len(frames) != 20:\n",
        "            print(f\"Warning: {subdir} has {len(frames)} frames, expected 20. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        for frame_name in frames:\n",
        "            img_path = os.path.join(subdir_path, frame_name)\n",
        "            image = cv2.imread(img_path)\n",
        "            if image is None:\n",
        "                print(f\"Error: Failed to load {img_path}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            image_resized = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
        "            image_rgb = cv2.cvtColor(image_resized, cv2.COLOR_BGR2RGB)\n",
        "            image_tensor = torch.from_numpy(image_rgb.transpose(2, 0, 1)).float() / 255.0\n",
        "            image_tensor = image_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                output = model(image_tensor)\n",
        "                mask = torch.argmax(output, dim=1).squeeze(0).cpu().numpy()\n",
        "\n",
        "            overlay_image = overlay_mask(image_resized, mask)\n",
        "            original_video.write(image_resized)\n",
        "            lane_video.write(overlay_image)\n",
        "            total_frames_processed += 1\n",
        "\n",
        "    # Release video writers after all subdirectories are processed\n",
        "    original_video.release()\n",
        "    lane_video.release()\n",
        "    print(f\"Generated single videos: 'original_video_all.mp4' and 'lane_detected_video_all.mp4'\")\n",
        "    print(f\"Total frames processed: {total_frames_processed}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-09T19:46:25.562646Z",
          "iopub.execute_input": "2025-04-09T19:46:25.562949Z",
          "iopub.status.idle": "2025-04-09T19:46:25.581703Z",
          "shell.execute_reply.started": "2025-04-09T19:46:25.562922Z",
          "shell.execute_reply": "2025-04-09T19:46:25.580872Z"
        },
        "id": "wCH5pKe9PMn2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = LaneNet(num_classes=NUM_CLASSES).to(device)\n",
        "model.load_state_dict(torch.load(\"/kaggle/input/models/lane_model_final (2).pth\", map_location=device,weights_only=True))\n",
        "model.eval()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-09T19:46:25.583577Z",
          "iopub.execute_input": "2025-04-09T19:46:25.583889Z",
          "iopub.status.idle": "2025-04-09T19:46:28.09636Z",
          "shell.execute_reply.started": "2025-04-09T19:46:25.583859Z",
          "shell.execute_reply": "2025-04-09T19:46:28.095415Z"
        },
        "id": "9cIe-8ftPMn3",
        "outputId": "33190962-a46b-4821-bfda-f9b58e62574d"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n100%|██████████| 83.3M/83.3M [00:00<00:00, 179MB/s]\n",
          "output_type": "stream"
        },
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "LaneNet(\n  (encoder): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (5): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (6): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (4): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (5): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (7): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (resa_layers): ModuleList(\n    (0-3): 4 x RESA(\n      (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (refine_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n      (refine_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (decoder): Decoder(\n    (Up1): Sequential(\n      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Upsample(scale_factor=2.0, mode='bilinear')\n    )\n    (Up2): Sequential(\n      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Upsample(scale_factor=2.0, mode='bilinear')\n    )\n    (smooth_conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)\n    (smooth_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (thin1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n    (thin2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n    (relu): ReLU(inplace=True)\n  )\n  (seg_head): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = \"/kaggle/input/tusimple/TUSimple/test_set/clips/0530\"  # Adjust to your directory\n",
        "process_directory(root_dir, model, device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-09T19:46:28.097573Z",
          "iopub.execute_input": "2025-04-09T19:46:28.097916Z",
          "iopub.status.idle": "2025-04-09T20:20:58.906934Z",
          "shell.execute_reply.started": "2025-04-09T19:46:28.097888Z",
          "shell.execute_reply": "2025-04-09T20:20:58.905887Z"
        },
        "id": "VfycgG13PMn3",
        "outputId": "6f4c4d3a-1ec8-4b7a-dbef-961ed663c1da"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Processing subdirectories: 100%|██████████| 1248/1248 [34:28<00:00,  1.66s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Generated single videos: 'original_video_all.mp4' and 'lane_detected_video_all.mp4'\nTotal frames processed: 24960\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "hIWlMX2GPMn4"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}